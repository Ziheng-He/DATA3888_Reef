}
X_combined = data %>% select(-average_bleaching)
y_combined = data %>% pull(average_bleaching)
cvK = 5    # Number of CV folds
n_sim = 50 # Number of repeats
cv_accuracy_overall = numeric(n_sim) # Vector to store averaged CV accuracies
for (i in 1:n_sim) {
cvSets = cvFolds(nrow(data), cvK) # Folds object for cross-validation
cv_accuracy_folds = numeric(cvK) # Vector to store accuracy for each fold
for (j in 1:cvK) {
test_id = cvSets$subsets[cvSets$which == j]
train = data[-test_id,] # Don't split training set to match glm syntax
X_test = X_combined[test_id,]
y_test = y_combined[test_id]
current_lr_fit = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
predicted_probs = predict(current_lr_fit, X_test,
type = "response") # Predicting probability of stable
predictions = ifelse(round(predicted_probs) == 1,
"Stable", "Rejection") # Converting probabilities into categories
cv_accuracy_folds[j] = accuracy(y_test, predictions)
}
cv_accuracy_overall[i] = mean(cv_accuracy_folds)
}
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(dplyr)
library(tidyverse)
library(sjPlot)
library(cvTools)
library(vcdExtra)
library(corrplot)
library(RColorBrewer)
library(caret)
# define training control
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
model <- train(target ~ .,
data = train,
trControl = train_control,
method = "glm",
family=binomial())
# define training control
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
model <- train(average_bleaching ~ .,
data = data,
trControl = train_control,
method = "glm",
family=binomial())
# define training control
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
summary(model)
accuracy <- function(true, predicted) {
# Calculates accuracy based on a vector of true labels and a vector of predictions
return(sum(true == predicted)/length(true))
}
X_combined = data %>% select(-bleached)
y_combined = data %>% pull(bleached)
cvK = 5    # Number of CV folds
n_sim = 50 # Number of repeats
cv_accuracy_overall = numeric(n_sim) # Vector to store averaged CV accuracies
for (i in 1:n_sim) {
cvSets = cvFolds(nrow(data), cvK) # Folds object for cross-validation
cv_accuracy_folds = numeric(cvK) # Vector to store accuracy for each fold
for (j in 1:cvK) {
test_id = cvSets$subsets[cvSets$which == j]
train = data[-test_id,] # Don't split training set to match glm syntax
X_test = X_combined[test_id,]
y_test = y_combined[test_id]
current_lr_fit = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
predicted_probs = predict(current_lr_fit, X_test,
type = "response") # Predicting probability of stable
predictions = ifelse(round(predicted_probs) == 1,
"Stable", "Rejection") # Converting probabilities into categories
cv_accuracy_folds[j] = accuracy(y_test, predictions)
}
cv_accuracy_overall[i] = mean(cv_accuracy_folds)
}
round(mean(cv_accuracy_overall),2)
# define training control
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
summary(model)
# define training control
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
print(model)
# define training control
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
print(model)
model$resample
# define training control
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
print(model)
model
model$resample
pred <- model$pred
pred$equal <- ifelse(pred$pred == pred$obs, 1,0)
eachfold <- pred %>%
group_by(Resample) %>%
summarise_at(vars(equal),
list(Accuracy = mean))
# define training control
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
print(model)
model$resample
round(mean(model),2)
# define training control
train_control <- trainControl(method = "cv", number = 10)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
print(model)
model$resample
mean(model)
# define training control
train_control <- trainControl(method = "cv", number = 10, savePredictions = TRUE)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
print(model)
model$resample
pred <- predict(model, newdata=testing)
pred <- predict(model, newdata=train)
confusionMatrix(data=pred, testing$Class)
pred <- predict(model, newdata=train)
confusionMatrix(data=pred, train$Class)
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(dplyr)
library(tidyverse)
library(sjPlot)
library(cvTools)
library(vcdExtra)
library(corrplot)
library(RColorBrewer)
library(caret)
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
summary(glm)
glm
## clean variable names
data = new_reef %>% janitor::clean_names()
names(data)
data
data
sample_10% <- data[sample(1:nrow(data), 50,
data
sample_10 <- data[sample(1:nrow(data), 50,
replace=FALSE),]
sample_10 <- data[sample(1:nrow(data), 50,
replace=FALSE),]
sample_10 <- data[sample(1:nrow(data), 27,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(dplyr)
library(tidyverse)
library(sjPlot)
library(cvTools)
library(vcdExtra)
library(corrplot)
library(RColorBrewer)
library(caret)
reef = read_csv("Data/Reef_Check_with_cortad_variables_with_annual_rate_of_SST_change.csv")
new_reef = read_csv("Data/lr_version_merged_mean.csv")
# Check what the reef dataset looks like
head(new_reef)
## clean variable names
data = new_reef %>% janitor::clean_names()
names(data)
## removing NA data entries
data <- na.omit(data)
## changing date to date
# data$date <- as.Date(data$date, format = "%d-%b-%y")
## changing temperature to celcius
data$temperature_celcius <- data$temperature_kelvin - 273.15
## longitude and latitude maximum and minimum to match dataset
# We have to sort out bleached and not bleached corals
data$bleached <- ifelse(data$average_bleaching > 0, "1", "0")
# 0 = not bleached
# 1 = bleached
data %>% count(bleached)
# Convert to numeric
data$bleached <- as.numeric(data$bleached)
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
summary(glm)
glm
## gets 0?
accuracy <- function(true, predicted) {
# Calculates accuracy based on a vector of true labels and a vector of predictions
return(sum(true == predicted)/length(true))
}
X_combined = data %>% select(-bleached)
y_combined = data %>% pull(bleached)
cvK = 5    # Number of CV folds
n_sim = 50 # Number of repeats
cv_accuracy_overall = numeric(n_sim) # Vector to store averaged CV accuracies
for (i in 1:n_sim) {
cvSets = cvFolds(nrow(data), cvK) # Folds object for cross-validation
cv_accuracy_folds = numeric(cvK) # Vector to store accuracy for each fold
for (j in 1:cvK) {
test_id = cvSets$subsets[cvSets$which == j]
train = data[-test_id,] # Don't split training set to match glm syntax
X_test = X_combined[test_id,]
y_test = y_combined[test_id]
current_lr_fit = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
predicted_probs = predict(current_lr_fit, X_test,
type = "response") # Predicting probability of stable
predictions = ifelse(round(predicted_probs) == 1,
"Stable", "Rejection") # Converting probabilities into categories
cv_accuracy_folds[j] = accuracy(y_test, predictions)
}
cv_accuracy_overall[i] = mean(cv_accuracy_folds)
}
round(mean(cv_accuracy_overall),2)
# define training control
train_control <- trainControl(method = "cv", number = 10, savePredictions = TRUE)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
print(model)
model$resample
sample_10 <- data[sample(1:nrow(data), 27,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
end_time <- Sys.time()
end_time - start_time
sample_10 <- data[sample(1:nrow(data), 27,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = sample_10)
end_time <- Sys.time()
end_time - start_time
sample_50 <- data[sample(1:nrow(data), 135,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = sample_50)
end_time <- Sys.time()
end_time - start_time
sample_70 <- data[sample(1:nrow(data), 189,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = sample_70)
end_time <- Sys.time()
end_time - start_time
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
end_time <- Sys.time()
end_time - start_time
sample_10 <- data[sample(1:nrow(data), 27,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = sample_10)
end_time <- Sys.time()
end_time - start_time
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(dplyr)
library(tidyverse)
library(sjPlot)
library(cvTools)
library(vcdExtra)
library(corrplot)
library(RColorBrewer)
library(caret)
reef = read_csv("Data/Reef_Check_with_cortad_variables_with_annual_rate_of_SST_change.csv")
new_reef = read_csv("Data/lr_version_merged_mean.csv")
# Check what the reef dataset looks like
head(new_reef)
## clean variable names
data = new_reef %>% janitor::clean_names()
names(data)
## removing NA data entries
data <- na.omit(data)
## changing date to date
# data$date <- as.Date(data$date, format = "%d-%b-%y")
## changing temperature to celcius
data$temperature_celcius <- data$temperature_kelvin - 273.15
## longitude and latitude maximum and minimum to match dataset
# We have to sort out bleached and not bleached corals
data$bleached <- ifelse(data$average_bleaching > 0, "1", "0")
# 0 = not bleached
# 1 = bleached
data %>% count(bleached)
# Convert to numeric
data$bleached <- as.numeric(data$bleached)
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
summary(glm)
glm
## gets 0?
accuracy <- function(true, predicted) {
# Calculates accuracy based on a vector of true labels and a vector of predictions
return(sum(true == predicted)/length(true))
}
X_combined = data %>% select(-bleached)
y_combined = data %>% pull(bleached)
cvK = 5    # Number of CV folds
n_sim = 50 # Number of repeats
cv_accuracy_overall = numeric(n_sim) # Vector to store averaged CV accuracies
for (i in 1:n_sim) {
cvSets = cvFolds(nrow(data), cvK) # Folds object for cross-validation
cv_accuracy_folds = numeric(cvK) # Vector to store accuracy for each fold
for (j in 1:cvK) {
test_id = cvSets$subsets[cvSets$which == j]
train = data[-test_id,] # Don't split training set to match glm syntax
X_test = X_combined[test_id,]
y_test = y_combined[test_id]
current_lr_fit = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
predicted_probs = predict(current_lr_fit, X_test,
type = "response") # Predicting probability of stable
predictions = ifelse(round(predicted_probs) == 1,
"Stable", "Rejection") # Converting probabilities into categories
cv_accuracy_folds[j] = accuracy(y_test, predictions)
}
cv_accuracy_overall[i] = mean(cv_accuracy_folds)
}
round(mean(cv_accuracy_overall),2)
# define training control
train_control <- trainControl(method = "cv", number = 10, savePredictions = TRUE)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
print(model)
model$resample
sample_10 <- data[sample(1:nrow(data), 27,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = sample_10)
end_time <- Sys.time()
end_time - start_time
sample_50 <- data[sample(1:nrow(data), 135,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = sample_50)
end_time <- Sys.time()
end_time - start_time
sample_70 <- data[sample(1:nrow(data), 189,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = sample_70)
end_time <- Sys.time()
end_time - start_time
#Sampling 10% of the data
sample_10 <- data[sample(1:nrow(data), 10%,
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(dplyr)
library(tidyverse)
library(sjPlot)
library(cvTools)
library(vcdExtra)
library(corrplot)
library(RColorBrewer)
library(caret)
reef = read_csv("Data/Reef_Check_with_cortad_variables_with_annual_rate_of_SST_change.csv")
new_reef = read_csv("Data/lr_version_merged_mean.csv")
# Check what the reef dataset looks like
head(new_reef)
## clean variable names
data = new_reef %>% janitor::clean_names()
names(data)
## removing NA data entries
data <- na.omit(data)
## changing date to date
# data$date <- as.Date(data$date, format = "%d-%b-%y")
## changing temperature to celcius
data$temperature_celcius <- data$temperature_kelvin - 273.15
## longitude and latitude maximum and minimum to match dataset
# We have to sort out bleached and not bleached corals
data$bleached <- ifelse(data$average_bleaching > 0, "1", "0")
# 0 = not bleached
# 1 = bleached
data %>% count(bleached)
# Convert to numeric
data$bleached <- as.numeric(data$bleached)
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
summary(glm)
glm
## gets 0?
accuracy <- function(true, predicted) {
# Calculates accuracy based on a vector of true labels and a vector of predictions
return(sum(true == predicted)/length(true))
}
X_combined = data %>% select(-bleached)
y_combined = data %>% pull(bleached)
cvK = 5    # Number of CV folds
n_sim = 50 # Number of repeats
cv_accuracy_overall = numeric(n_sim) # Vector to store averaged CV accuracies
for (i in 1:n_sim) {
cvSets = cvFolds(nrow(data), cvK) # Folds object for cross-validation
cv_accuracy_folds = numeric(cvK) # Vector to store accuracy for each fold
for (j in 1:cvK) {
test_id = cvSets$subsets[cvSets$which == j]
train = data[-test_id,] # Don't split training set to match glm syntax
X_test = X_combined[test_id,]
y_test = y_combined[test_id]
current_lr_fit = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
predicted_probs = predict(current_lr_fit, X_test,
type = "response") # Predicting probability of stable
predictions = ifelse(round(predicted_probs) == 1,
"Stable", "Rejection") # Converting probabilities into categories
cv_accuracy_folds[j] = accuracy(y_test, predictions)
}
cv_accuracy_overall[i] = mean(cv_accuracy_folds)
}
round(mean(cv_accuracy_overall),2)
# define training control
train_control <- trainControl(method = "cv", number = 10, savePredictions = TRUE)
# train the model on training set
model <- train(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur,
data = data,
method = "glm",
trControl = train_control,
family=binomial())
# print cv scores
print(model)
model$resample
#Sampling 10% of the data
sample_10 <- data[sample(1:nrow(data), 27,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = sample_10)
end_time <- Sys.time()
end_time - start_time
#sampling 50% of data
sample_50 <- data[sample(1:nrow(data), 135,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = sample_50)
end_time <- Sys.time()
end_time - start_time
#sampling 70% of data
sample_70 <- data[sample(1:nrow(data), 189,
replace=FALSE),]
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = sample_70)
end_time <- Sys.time()
end_time - start_time
#the whole data
start_time <- Sys.time()
glm = glm(bleached ~ clim_sst + temperature_kelvin + temperature_kelvin_standard_deviation + ssta_frequency + ssta_frequency_standard_deviation + tsa_frequency_standard_deviation + mean_cur, family = binomial, data = data)
end_time <- Sys.time()
end_time - start_time
path = "./Models/logistic"
model_rds_path = paste(path, ".rds",sep='')
model_dep_path = paste(path, ".dep",sep='')
DEP_LIBS = c("caret")
# save model
saveRDS(model, model_rds_path)
# save dependency list
file_conn <- file(model_dep_path)
writeLines("",file_conn)
close(file_conn)
